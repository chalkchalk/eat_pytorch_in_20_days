{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750b7918",
   "metadata": {},
   "source": [
    "# 4-2,张量的数学运算\n",
    "\n",
    "张量的操作主要包括张量的结构操作和张量的数学运算。\n",
    "\n",
    "张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。\n",
    "\n",
    "张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。\n",
    "\n",
    "本篇我们介绍张量的数学运算。\n",
    "\n",
    "本篇文章部分内容参考如下博客：https://blog.csdn.net/duan_zhihua/article/details/82526505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ebfee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba27bdec",
   "metadata": {},
   "source": [
    "### 一，标量运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226815d8",
   "metadata": {},
   "source": [
    "张量的数学运算符可以分为标量运算符、向量运算符、以及矩阵运算符。\n",
    "\n",
    "加减乘除乘方，以及三角函数，指数，对数等常见函数，逻辑比较运算符等都是标量运算符。\n",
    "\n",
    "标量运算符的特点是对张量实施逐元素运算。\n",
    "\n",
    "有些标量运算符对常用的数学运算符进行了重载。并且支持类似numpy的广播特性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8721856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9683507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  8.],\n",
       "        [ 4., 12.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1.0,2],[-3,4.0]])\n",
    "b = torch.tensor([[5.0,6],[7.0,8.0]])\n",
    "a+b  #运算符重载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a739f8",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[ 6.,  8.],\n",
    "        [ 4., 12.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0728cda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [-3.,  4.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a43bf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf76221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7924ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec481b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "a-b "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c4e6e",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[ -4.,  -4.],\n",
    "        [-10.,  -4.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa8ba19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5.,  12.],\n",
       "        [-21.,  32.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d279491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 22.],\n",
       "        [13., 14.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ada50",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[  5.,  12.],\n",
    "        [-21.,  32.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a/b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9417864",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[ 0.2000,  0.3333],\n",
    "        [-0.4286,  0.5000]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7841564",
   "metadata": {},
   "outputs": [],
   "source": [
    "a**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c4919",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[ 1.,  4.],\n",
    "        [ 9., 16.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f71adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a**(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73eb043",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[1.0000, 1.4142],\n",
    "        [   nan, 2.0000]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98520235",
   "metadata": {},
   "outputs": [],
   "source": [
    "a%3 #求模"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6326a859",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[1., 2.],\n",
    "        [0., 1.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "a//3  #地板除法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bb7a4",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[ 0.,  0.],\n",
    "        [-1.,  1.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a>=2 # torch.ge(a,2)  #ge: greater_equal缩写"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36ac6f",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[False,  True],\n",
    "        [False,  True]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a>=2)&(a<=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e718d35",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[False,  True],\n",
    "        [False, False]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a>=2)|(a<=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d26ee5",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[True, True],\n",
    "        [True, True]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fcaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "a==5 #torch.eq(a,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762bdc2",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[False, False],\n",
    "        [False, False]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sqrt(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f24c579",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[1.0000, 1.4142],\n",
    "        [   nan, 2.0000]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1.0,8.0])\n",
    "b = torch.tensor([5.0,6.0])\n",
    "c = torch.tensor([6.0,7.0])\n",
    "\n",
    "d = a+b+c\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87afae",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([12., 21.])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.max(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f8154",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([5., 8.])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6752ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.min(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f9c2b",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([1., 6.])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.6,-2.7])\n",
    "\n",
    "print(torch.round(x)) #保留整数部分，四舍五入\n",
    "print(torch.floor(x)) #保留整数部分，向下归整\n",
    "print(torch.ceil(x))  #保留整数部分，向上归整\n",
    "print(torch.trunc(x)) #保留整数部分，向0归整"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003882c0",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([ 3., -3.])\n",
    "tensor([ 2., -3.])\n",
    "tensor([ 3., -2.])\n",
    "tensor([ 2., -2.])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f81849",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.6,-2.7])\n",
    "print(torch.fmod(x,2)) #作除法取余数 \n",
    "print(torch.remainder(x,2)) #作除法取剩余的部分，结果恒正"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129dc0a",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([ 0.6000, -0.7000])\n",
    "tensor([0.6000, 1.3000])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d47eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 幅值裁剪\n",
    "x = torch.tensor([0.9,-0.8,100.0,-20.0,0.7])\n",
    "y = torch.clamp(x,min=-1,max = 1)\n",
    "z = torch.clamp(x,max = 1)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d40da1",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([ 0.9000, -0.8000,  1.0000, -1.0000,  0.7000])\n",
    "tensor([  0.9000,  -0.8000,   1.0000, -20.0000,   0.7000])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77578e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4233283c",
   "metadata": {},
   "source": [
    "### 二，向量运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381cd3f",
   "metadata": {},
   "source": [
    "向量运算符只在一个特定轴上运算，将一个向量映射到一个标量或者另外一个向量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45581abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.)\n",
      "tensor(5.)\n",
      "tensor(9.)\n",
      "tensor(1.)\n",
      "tensor(362880.)\n",
      "tensor(2.7386)\n",
      "tensor(7.5000)\n",
      "tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "#统计值\n",
    "\n",
    "a = torch.arange(1,10).float()\n",
    "print(torch.sum(a))\n",
    "print(torch.mean(a))\n",
    "print(torch.max(a))\n",
    "print(torch.min(a))\n",
    "print(torch.prod(a)) #累乘\n",
    "print(torch.std(a))  #标准差\n",
    "print(torch.var(a))  #方差\n",
    "print(torch.median(a)) #中位数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e50b0",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(45.)\n",
    "tensor(5.)\n",
    "tensor(9.)\n",
    "tensor(1.)\n",
    "tensor(362880.)\n",
    "tensor(2.7386)\n",
    "tensor(7.5000)\n",
    "tensor(5.)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7bae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor(9.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 6., 9.]),\n",
      "indices=tensor([2, 2, 2]))\n"
     ]
    }
   ],
   "source": [
    "#指定维度计算统计值\n",
    "\n",
    "b = a.view(3,3)\n",
    "print(b)\n",
    "print(torch.max(b))\n",
    "print(torch.max(b,dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e498f26",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[1., 2., 3.],\n",
    "        [4., 5., 6.],\n",
    "        [7., 8., 9.]])\n",
    "torch.return_types.max(\n",
    "values=tensor([7., 8., 9.]),\n",
    "indices=tensor([2, 2, 2]))\n",
    "torch.return_types.max(\n",
    "values=tensor([3., 6., 9.]),\n",
    "indices=tensor([2, 2, 2]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be5213f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  3,  6, 10, 15, 21, 28, 36, 45])\n",
      "tensor([     1,      2,      6,     24,    120,    720,   5040,  40320, 362880])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "torch.return_types.cummin(\n",
      "values=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "#cum扫描\n",
    "a = torch.arange(1,10)\n",
    "\n",
    "print(torch.cumsum(a,0))\n",
    "print(torch.cumprod(a,0))\n",
    "print(torch.cummax(a,0).values)\n",
    "print(torch.cummax(a,0).indices)\n",
    "print(torch.cummin(a,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ddb43",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([ 1,  3,  6, 10, 15, 21, 28, 36, 45])\n",
    "tensor([     1,      2,      6,     24,    120,    720,   5040,  40320, 362880])\n",
    "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "torch.return_types.cummin(\n",
    "values=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
    "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db469810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.return_types.topk(\n",
      "values=tensor([[9., 7., 8.],\n",
      "        [5., 6., 4.]]),\n",
      "indices=tensor([[0, 0, 0],\n",
      "        [2, 2, 2]])) \n",
      "\n",
      "torch.return_types.topk(\n",
      "values=tensor([[9., 8.],\n",
      "        [3., 2.],\n",
      "        [6., 5.]]),\n",
      "indices=tensor([[0, 2],\n",
      "        [1, 2],\n",
      "        [1, 0]])) \n",
      "\n",
      "torch.return_types.sort(\n",
      "values=tensor([[7., 8., 9.],\n",
      "        [1., 2., 3.],\n",
      "        [4., 5., 6.]]),\n",
      "indices=tensor([[1, 2, 0],\n",
      "        [0, 2, 1],\n",
      "        [2, 0, 1]])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#torch.sort和torch.topk可以对张量排序\n",
    "a = torch.tensor([[9,7,8],[1,3,2],[5,6,4]]).float()\n",
    "print(a.shape)\n",
    "print(torch.topk(a,2,dim = 0),\"\\n\")\n",
    "print(torch.topk(a,2,dim = 1),\"\\n\")\n",
    "print(torch.sort(a,dim = 1),\"\\n\")\n",
    "\n",
    "#利用torch.topk可以在Pytorch中实现KNN算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674d86b",
   "metadata": {},
   "source": [
    "```\n",
    "torch.return_types.topk(\n",
    "values=tensor([[9., 7., 8.],\n",
    "        [5., 6., 4.]]),\n",
    "indices=tensor([[0, 0, 0],\n",
    "        [2, 2, 2]]))\n",
    "\n",
    "torch.return_types.topk(\n",
    "values=tensor([[9., 8.],\n",
    "        [3., 2.],\n",
    "        [6., 5.]]),\n",
    "indices=tensor([[0, 2],\n",
    "        [1, 2],\n",
    "        [1, 0]]))\n",
    "\n",
    "torch.return_types.sort(\n",
    "values=tensor([[7., 8., 9.],\n",
    "        [1., 2., 3.],\n",
    "        [4., 5., 6.]]),\n",
    "indices=tensor([[1, 2, 0],\n",
    "        [0, 2, 1],\n",
    "        [2, 0, 1]]))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e56fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47b1a415",
   "metadata": {},
   "source": [
    "### 三，矩阵运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1b198",
   "metadata": {},
   "source": [
    "矩阵必须是二维的。类似torch.tensor([1,2,3])这样的不是矩阵。\n",
    "\n",
    "矩阵运算包括：矩阵乘法，矩阵转置，矩阵逆，矩阵求迹，矩阵范数，矩阵行列式，矩阵求特征值，矩阵分解等运算。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵乘法\n",
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = torch.tensor([[2,0],[0,2]])\n",
    "print(a@b)  #等价于torch.matmul(a,b) 或 torch.mm(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc798c91",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[2, 4],\n",
    "        [6, 8]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd99664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵转置\n",
    "a = torch.tensor([[1.0,2],[3,4]])\n",
    "print(a.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ef54a",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[1., 3.],\n",
    "        [2., 4.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b39d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵逆，必须为浮点类型\n",
    "a = torch.tensor([[1.0,2],[3,4]])\n",
    "print(torch.inverse(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1e625",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[-2.0000,  1.0000],\n",
    "        [ 1.5000, -0.5000]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b849659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵求trace\n",
    "a = torch.tensor([[1.0,2],[3,4]])\n",
    "print(torch.trace(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1df996",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(5.)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98022302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵求范数\n",
    "a = torch.tensor([[1.0,2],[3,4]])\n",
    "print(torch.norm(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b2b57",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(5.4772)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵行列式\n",
    "a = torch.tensor([[1.0,2],[3,4]])\n",
    "print(torch.det(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e4254",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(-2.0000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵特征值和特征向量\n",
    "a = torch.tensor([[1.0,2],[-5,4]],dtype = torch.float)\n",
    "print(torch.eig(a,eigenvectors=True))\n",
    "\n",
    "#两个特征值分别是 -2.5+2.7839j, 2.5-2.7839j "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6461f",
   "metadata": {},
   "source": [
    "```\n",
    "torch.return_types.eig(\n",
    "eigenvalues=tensor([[ 2.5000,  2.7839],\n",
    "        [ 2.5000, -2.7839]]),\n",
    "eigenvectors=tensor([[ 0.2535, -0.4706],\n",
    "        [ 0.8452,  0.0000]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf39373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵QR分解, 将一个方阵分解为一个正交矩阵q和上三角矩阵r\n",
    "#QR分解实际上是对矩阵a实施Schmidt正交化得到q\n",
    "\n",
    "a  = torch.tensor([[1.0,2.0],[3.0,4.0]])\n",
    "q,r = torch.qr(a)\n",
    "print(q,\"\\n\")\n",
    "print(r,\"\\n\")\n",
    "print(q@r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae3bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵svd分解\n",
    "#svd分解可以将任意一个矩阵分解为一个正交矩阵u,一个对角阵s和一个正交矩阵v.t()的乘积\n",
    "#svd常用于矩阵压缩和降维\n",
    "a=torch.tensor([[1.0,2.0],[3.0,4.0],[5.0,6.0]])\n",
    "\n",
    "u,s,v = torch.svd(a)\n",
    "\n",
    "print(u,\"\\n\")\n",
    "print(s,\"\\n\")\n",
    "print(v,\"\\n\")\n",
    "\n",
    "print(u@torch.diag(s)@v.t())\n",
    "\n",
    "#利用svd分解可以在Pytorch中实现主成分分析降维\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d59aef",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[-0.2298,  0.8835],\n",
    "        [-0.5247,  0.2408],\n",
    "        [-0.8196, -0.4019]]) \n",
    "\n",
    "tensor([9.5255, 0.5143]) \n",
    "\n",
    "tensor([[-0.6196, -0.7849],\n",
    "        [-0.7849,  0.6196]]) \n",
    "\n",
    "tensor([[1.0000, 2.0000],\n",
    "        [3.0000, 4.0000],\n",
    "        [5.0000, 6.0000]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a766c719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20643f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "584f76ff",
   "metadata": {},
   "source": [
    "### 四，广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422682b",
   "metadata": {},
   "source": [
    "Pytorch的广播规则和numpy是一样的:\n",
    "\n",
    "* 1、如果张量的维度不同，将维度较小的张量进行扩展，直到两个张量的维度都一样。\n",
    "* 2、如果两个张量在某个维度上的长度是相同的，或者其中一个张量在该维度上的长度为1，那么我们就说这两个张量在该维度上是相容的。\n",
    "* 3、如果两个张量在所有维度上都是相容的，它们就能使用广播。\n",
    "* 4、广播之后，每个维度的长度将取两个张量在该维度长度的较大值。\n",
    "* 5、在任何一个维度上，如果一个张量的长度为1，另一个张量长度大于1，那么在该维度上，就好像是对第一个张量进行了复制。\n",
    "\n",
    "torch.broadcast_tensors可以将多个张量根据广播规则转换成相同的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29618f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([[0,0,0],[1,1,1],[2,2,2]])\n",
    "print(b + a) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f610b",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[1, 2, 3],\n",
    "        [2, 3, 4],\n",
    "        [3, 4, 5]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_broad,b_broad = torch.broadcast_tensors(a,b)\n",
    "print(a_broad,\"\\n\")\n",
    "print(b_broad,\"\\n\")\n",
    "print(a_broad + b_broad) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651cb7a5",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[1, 2, 3],\n",
    "        [1, 2, 3],\n",
    "        [1, 2, 3]]) \n",
    "\n",
    "tensor([[0, 0, 0],\n",
    "        [1, 1, 1],\n",
    "        [2, 2, 2]]) \n",
    "\n",
    "tensor([[1, 2, 3],\n",
    "        [2, 3, 4],\n",
    "        [3, 4, 5]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c8780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdf4d516",
   "metadata": {},
   "source": [
    "**如果本书对你有所帮助，想鼓励一下作者，记得给本项目加一颗星星star⭐️，并分享给你的朋友们喔😊!** \n",
    "\n",
    "如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n",
    "\n",
    "也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n",
    "\n",
    "![算法美食屋logo.png](./data/算法美食屋二维码.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cc7b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
