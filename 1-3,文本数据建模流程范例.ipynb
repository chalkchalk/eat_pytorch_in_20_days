{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9171c84d",
   "metadata": {},
   "source": [
    "# 1-3,文本数据建模流程范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea014cc",
   "metadata": {},
   "source": [
    "### 一，准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7622ab8",
   "metadata": {},
   "source": [
    "imdb数据集的目标是根据电影评论的文本内容预测评论的情感标签。\n",
    "\n",
    "训练集有20000条电影评论文本，测试集有5000条电影评论文本，其中正面评论和负面评论都各占一半。\n",
    "\n",
    "文本数据预处理较为繁琐，包括中文切词（本示例不涉及），构建词典，编码转换，序列填充，构建数据管道等等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ecdb9e",
   "metadata": {},
   "source": [
    "在torch中预处理文本数据一般使用torchtext或者自定义Dataset，torchtext功能非常强大，可以构建文本分类，序列标注，问答模型，机器翻译等NLP任务的数据集。\n",
    "\n",
    "下面仅演示使用它来构建文本分类数据集的方法。\n",
    "\n",
    "较完整的教程可以参考以下知乎文章：《pytorch学习笔记—Torchtext》\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/65833208"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603ecfa",
   "metadata": {},
   "source": [
    "![](./data/电影评论.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34193b4",
   "metadata": {},
   "source": [
    "torchtext常见API一览\n",
    "\n",
    "* torchtext.data.Example : 用来表示一个样本，数据和标签\n",
    "* torchtext.vocab.Vocab: 词汇表，可以导入一些预训练词向量\n",
    "* torchtext.data.Datasets: 数据集类，`__getitem__`返回 Example实例, torchtext.data.TabularDataset是其子类。\n",
    "* torchtext.data.Field : 用来定义字段的处理方法（文本字段，标签字段）创建 Example时的 预处理，batch 时的一些处理操作。\n",
    "* torchtext.data.Iterator: 迭代器，用来生成 batch\n",
    "* torchtext.datasets: 包含了常见的数据集.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8cb1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string,re\n",
    "import torchtext\n",
    "\n",
    "MAX_WORDS = 10000  # 仅考虑最高频的10000个词\n",
    "MAX_LEN = 200  # 每个样本保留200个词的长度\n",
    "BATCH_SIZE = 20 \n",
    "\n",
    "#分词方法\n",
    "tokenizer = lambda x:re.sub('[%s]'%string.punctuation,\"\",x).split(\" \")\n",
    "\n",
    "#过滤掉低频词\n",
    "def filterLowFreqWords(arr,vocab):\n",
    "    arr = [[x if x<MAX_WORDS else 0 for x in example] \n",
    "           for example in arr]\n",
    "    return arr\n",
    "\n",
    "#1,定义各个字段的预处理方法\n",
    "TEXT = torchtext.legacy.data.Field(sequential=True, tokenize=tokenizer, lower=True, \n",
    "                  fix_length=MAX_LEN,postprocessing = filterLowFreqWords)\n",
    "\n",
    "LABEL = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "#2,构建表格型dataset\n",
    "#torchtext.data.TabularDataset可读取csv,tsv,json等格式\n",
    "ds_train, ds_valid = torchtext.legacy.data.TabularDataset.splits(\n",
    "        path='./data/imdb', train='train.tsv',test='test.tsv', format='tsv',\n",
    "        fields=[('label', LABEL), ('text', TEXT)],skip_header = False)\n",
    "\n",
    "#3,构建词典\n",
    "TEXT.build_vocab(ds_train)\n",
    "\n",
    "#4,构建数据管道迭代器\n",
    "train_iter, valid_iter = torchtext.legacy.data.Iterator.splits(\n",
    "        (ds_train, ds_valid),  sort_within_batch=True,sort_key=lambda x: len(x.text),\n",
    "        batch_sizes=(BATCH_SIZE,BATCH_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeabab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'really', 'boggles', 'my', 'mind', 'when', 'someone', 'comes', 'across', 'a', 'movie', 'like', 'this', 'and', 'claims', 'it', 'to', 'be', 'one', 'of', 'the', 'worst', 'slasher', 'films', 'out', 'there', 'this', 'is', 'by', 'far', 'not', 'one', 'of', 'the', 'worst', 'out', 'there', 'still', 'not', 'a', 'good', 'movie', 'but', 'not', 'the', 'worst', 'nonetheless', 'go', 'see', 'something', 'like', 'death', 'nurse', 'or', 'blood', 'lake', 'and', 'then', 'come', 'back', 'to', 'me', 'and', 'tell', 'me', 'if', 'you', 'think', 'the', 'night', 'brings', 'charlie', 'is', 'the', 'worst', 'the', 'film', 'has', 'decent', 'camera', 'work', 'and', 'editing', 'which', 'is', 'way', 'more', 'than', 'i', 'can', 'say', 'for', 'many', 'more', 'extremely', 'obscure', 'slasher', 'filmsbr', 'br', 'the', 'film', 'doesnt', 'deliver', 'on', 'the', 'onscreen', 'deaths', 'theres', 'one', 'death', 'where', 'you', 'see', 'his', 'pruning', 'saw', 'rip', 'into', 'a', 'neck', 'but', 'all', 'other', 'deaths', 'are', 'hardly', 'interesting', 'but', 'the', 'lack', 'of', 'onscreen', 'graphic', 'violence', 'doesnt', 'mean', 'this', 'isnt', 'a', 'slasher', 'film', 'just', 'a', 'bad', 'onebr', 'br', 'the', 'film', 'was', 'obviously', 'intended', 'not', 'to', 'be', 'taken', 'too', 'seriously', 'the', 'film', 'came', 'in', 'at', 'the', 'end', 'of', 'the', 'second', 'slasher', 'cycle', 'so', 'it', 'certainly', 'was', 'a', 'reflection', 'on', 'traditional', 'slasher', 'elements', 'done', 'in', 'a', 'tongue', 'in', 'cheek', 'way', 'for', 'example', 'after', 'a', 'kill', 'charlie', 'goes', 'to', 'the', 'towns', 'welcome', 'sign', 'and', 'marks', 'the', 'population', 'down', 'one', 'less', 'this', 'is', 'something', 'that', 'can', 'only', 'get', 'a', 'laughbr', 'br', 'if', 'youre', 'into', 'slasher', 'films', 'definitely', 'give', 'this', 'film', 'a', 'watch', 'it', 'is', 'slightly', 'different', 'than', 'your', 'usual', 'slasher', 'film', 'with', 'possibility', 'of', 'two', 'killers', 'but', 'not', 'by', 'much', 'the', 'comedy', 'of', 'the', 'movie', 'is', 'pretty', 'much', 'telling', 'the', 'audience', 'to', 'relax', 'and', 'not', 'take', 'the', 'movie', 'so', 'god', 'darn', 'serious', 'you', 'may', 'forget', 'the', 'movie', 'you', 'may', 'remember', 'it', 'ill', 'remember', 'it', 'because', 'i', 'love', 'the', 'name']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#查看example信息\n",
    "print(ds_train[0].text)\n",
    "print(ds_train[0].label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b28f4eb",
   "metadata": {},
   "source": [
    "```\n",
    "['it', 'really', 'boggles', 'my', 'mind', 'when', 'someone', 'comes', 'across', 'a', 'movie', 'like', 'this', 'and', 'claims', 'it', 'to', 'be', 'one', 'of', 'the', 'worst', 'slasher', 'films', 'out', 'there', 'this', 'is', 'by', 'far', 'not', 'one', 'of', 'the', 'worst', 'out', 'there', 'still', 'not', 'a', 'good', 'movie', 'but', 'not', 'the', 'worst', 'nonetheless', 'go', 'see', 'something', 'like', 'death', 'nurse', 'or', 'blood', 'lake', 'and', 'then', 'come', 'back', 'to', 'me', 'and', 'tell', 'me', 'if', 'you', 'think', 'the', 'night', 'brings', 'charlie', 'is', 'the', 'worst', 'the', 'film', 'has', 'decent', 'camera', 'work', 'and', 'editing', 'which', 'is', 'way', 'more', 'than', 'i', 'can', 'say', 'for', 'many', 'more', 'extremely', 'obscure', 'slasher', 'filmsbr', 'br', 'the', 'film', 'doesnt', 'deliver', 'on', 'the', 'onscreen', 'deaths', 'theres', 'one', 'death', 'where', 'you', 'see', 'his', 'pruning', 'saw', 'rip', 'into', 'a', 'neck', 'but', 'all', 'other', 'deaths', 'are', 'hardly', 'interesting', 'but', 'the', 'lack', 'of', 'onscreen', 'graphic', 'violence', 'doesnt', 'mean', 'this', 'isnt', 'a', 'slasher', 'film', 'just', 'a', 'bad', 'onebr', 'br', 'the', 'film', 'was', 'obviously', 'intended', 'not', 'to', 'be', 'taken', 'too', 'seriously', 'the', 'film', 'came', 'in', 'at', 'the', 'end', 'of', 'the', 'second', 'slasher', 'cycle', 'so', 'it', 'certainly', 'was', 'a', 'reflection', 'on', 'traditional', 'slasher', 'elements', 'done', 'in', 'a', 'tongue', 'in', 'cheek', 'way', 'for', 'example', 'after', 'a', 'kill', 'charlie', 'goes', 'to', 'the', 'towns', 'welcome', 'sign', 'and', 'marks', 'the', 'population', 'down', 'one', 'less', 'this', 'is', 'something', 'that', 'can', 'only', 'get', 'a', 'laughbr', 'br', 'if', 'youre', 'into', 'slasher', 'films', 'definitely', 'give', 'this', 'film', 'a', 'watch', 'it', 'is', 'slightly', 'different', 'than', 'your', 'usual', 'slasher', 'film', 'with', 'possibility', 'of', 'two', 'killers', 'but', 'not', 'by', 'much', 'the', 'comedy', 'of', 'the', 'movie', 'is', 'pretty', 'much', 'telling', 'the', 'audience', 'to', 'relax', 'and', 'not', 'take', 'the', 'movie', 'so', 'god', 'darn', 'serious', 'you', 'may', 'forget', 'the', 'movie', 'you', 'may', 'remember', 'it', 'ill', 'remember', 'it', 'because', 'i', 'love', 'the', 'name']\n",
    "0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1500b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108197\n",
      "<unk>\n",
      "<pad>\n",
      "0\n",
      "1\n",
      "0\n",
      "129453\n",
      "11457\n"
     ]
    }
   ],
   "source": [
    "# 查看词典信息\n",
    "print(len(TEXT.vocab))\n",
    "\n",
    "#itos: index to string\n",
    "print(TEXT.vocab.itos[0]) \n",
    "print(TEXT.vocab.itos[1]) \n",
    "\n",
    "#stoi: string to index\n",
    "print(TEXT.vocab.stoi['<unk>']) #unknown 未知词\n",
    "print(TEXT.vocab.stoi['<pad>']) #padding  填充\n",
    "\n",
    "\n",
    "#freqs: 词频\n",
    "print(TEXT.vocab.freqs['<unk>']) \n",
    "print(TEXT.vocab.freqs['a']) \n",
    "print(TEXT.vocab.freqs['good']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b2dca",
   "metadata": {},
   "source": [
    "```\n",
    "108197\n",
    "<unk>\n",
    "<pad>\n",
    "0\n",
    "1\n",
    "0\n",
    "129453\n",
    "11457\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e9218a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  62,    0,   75,  ...,  220,   75,   11],\n",
      "        [  82,    3,   11,  ...,   99,  217,    7],\n",
      "        [  23, 1980,   18,  ...,    5,   58,   29],\n",
      "        ...,\n",
      "        [ 208,    0,    4,  ...,    1,    1,    1],\n",
      "        [2120,    0,    0,  ...,    1,    1,    1],\n",
      "        [ 171,   37,    8,  ...,    1,    1,    1]])\n",
      "torch.Size([200, 20])\n",
      "tensor([1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# 查看数据管道信息\n",
    "# 注意有坑：text第0维是句子长度\n",
    "for batch in train_iter:\n",
    "    features = batch.text\n",
    "    labels = batch.label\n",
    "    print(features)\n",
    "    print(features.shape)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e431e2",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[  17,   31,  148,  ...,   54,   11,  201],\n",
    "        [   2,    2,  904,  ...,  335,    7,  109],\n",
    "        [1371, 1737,   44,  ...,  806,    2,   11],\n",
    "        ...,\n",
    "        [   6,    5,   62,  ...,    1,    1,    1],\n",
    "        [ 170,    0,   27,  ...,    1,    1,    1],\n",
    "        [  15,    0,   45,  ...,    1,    1,    1]])\n",
    "torch.Size([200, 20])\n",
    "tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "074e40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据管道组织成torch.utils.data.DataLoader相似的features,label输出形式\n",
    "class DataLoader:\n",
    "    def __init__(self,data_iter):\n",
    "        self.data_iter = data_iter\n",
    "        self.length = len(data_iter)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # 注意：此处调整features为 batch first，并调整label的shape和dtype\n",
    "        for batch in self.data_iter:\n",
    "            yield(torch.transpose(batch.text,0,1),\n",
    "                  torch.unsqueeze(batch.label.float(),dim = 1))\n",
    "    \n",
    "dl_train = DataLoader(train_iter)\n",
    "dl_valid = DataLoader(valid_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4307e7b6",
   "metadata": {},
   "source": [
    "### 二，定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68f91c",
   "metadata": {},
   "source": [
    "使用Pytorch通常有三种方式构建模型：使用nn.Sequential按层顺序构建模型，继承nn.Module基类构建自定义模型，继承nn.Module基类构建模型并辅助应用模型容器(nn.Sequential,nn.ModuleList,nn.ModuleDict)进行封装。\n",
    "\n",
    "此处选择使用第三种方式进行构建。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "949659a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torchkeras import LightModel,summary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ca23d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedding): Embedding(10000, 3, padding_idx=1)\n",
      "  (conv): Sequential(\n",
      "    (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))\n",
      "    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (relu_1): ReLU()\n",
      "    (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))\n",
      "    (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (relu_2): ReLU()\n",
      "  )\n",
      "  (dense): Sequential(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear): Linear(in_features=6144, out_features=1, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1               [-1, 200, 3]          30,000\n",
      "            Conv1d-2              [-1, 16, 196]             256\n",
      "         MaxPool1d-3               [-1, 16, 98]               0\n",
      "              ReLU-4               [-1, 16, 98]               0\n",
      "            Conv1d-5              [-1, 128, 97]           4,224\n",
      "         MaxPool1d-6              [-1, 128, 48]               0\n",
      "              ReLU-7              [-1, 128, 48]               0\n",
      "           Flatten-8                 [-1, 6144]               0\n",
      "            Linear-9                    [-1, 1]           6,145\n",
      "          Sigmoid-10                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 40,625\n",
      "Trainable params: 40,625\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.000763\n",
      "Forward/backward pass size (MB): 0.287796\n",
      "Params size (MB): 0.154972\n",
      "Estimated Total Size (MB): 0.443531\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.random.seed()\n",
    "import torch\n",
    "from torch import nn \n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #设置padding_idx参数后将在训练过程中将填充的token始终赋值为0向量\n",
    "        self.embedding = nn.Embedding(num_embeddings = MAX_WORDS,embedding_dim = 3,padding_idx = 1)\n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module(\"conv_1\",nn.Conv1d(in_channels = 3,out_channels = 16,kernel_size = 5))\n",
    "        self.conv.add_module(\"pool_1\",nn.MaxPool1d(kernel_size = 2))\n",
    "        self.conv.add_module(\"relu_1\",nn.ReLU())\n",
    "        self.conv.add_module(\"conv_2\",nn.Conv1d(in_channels = 16,out_channels = 128,kernel_size = 2))\n",
    "        self.conv.add_module(\"pool_2\",nn.MaxPool1d(kernel_size = 2))\n",
    "        self.conv.add_module(\"relu_2\",nn.ReLU())\n",
    "        \n",
    "        self.dense = nn.Sequential()\n",
    "        self.dense.add_module(\"flatten\",nn.Flatten())\n",
    "        self.dense.add_module(\"linear\",nn.Linear(6144,1))\n",
    "        self.dense.add_module(\"sigmoid\",nn.Sigmoid())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x).transpose(1,2)\n",
    "        x = self.conv(x)\n",
    "        y = self.dense(x)\n",
    "        return y\n",
    "        \n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "summary(net, input_shape = (200,),input_dtype = torch.LongTensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52557884",
   "metadata": {},
   "source": [
    "```\n",
    "Net(\n",
    "  (embedding): Embedding(10000, 3, padding_idx=1)\n",
    "  (conv): Sequential(\n",
    "    (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))\n",
    "    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (relu_1): ReLU()\n",
    "    (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))\n",
    "    (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (relu_2): ReLU()\n",
    "  )\n",
    "  (dense): Sequential(\n",
    "    (flatten): Flatten()\n",
    "    (linear): Linear(in_features=6144, out_features=1, bias=True)\n",
    "    (sigmoid): Sigmoid()\n",
    "  )\n",
    ")\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "         Embedding-1               [-1, 200, 3]          30,000\n",
    "            Conv1d-2              [-1, 16, 196]             256\n",
    "         MaxPool1d-3               [-1, 16, 98]               0\n",
    "              ReLU-4               [-1, 16, 98]               0\n",
    "            Conv1d-5              [-1, 128, 97]           4,224\n",
    "         MaxPool1d-6              [-1, 128, 48]               0\n",
    "              ReLU-7              [-1, 128, 48]               0\n",
    "           Flatten-8                 [-1, 6144]               0\n",
    "            Linear-9                    [-1, 1]           6,145\n",
    "          Sigmoid-10                    [-1, 1]               0\n",
    "================================================================\n",
    "Total params: 40,625\n",
    "Trainable params: 40,625\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.000763\n",
    "Forward/backward pass size (MB): 0.287796\n",
    "Params size (MB): 0.154972\n",
    "Estimated Total Size (MB): 0.443531\n",
    "----------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b976b3",
   "metadata": {},
   "source": [
    "### 三，训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a50703",
   "metadata": {},
   "source": [
    "训练Pytorch通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。\n",
    "\n",
    "有3类典型的训练循环代码风格：脚本形式训练循环，函数形式训练循环，类形式训练循环。\n",
    "\n",
    "此处介绍一种类形式的训练循环。\n",
    "\n",
    "我们利用Pytorch-Lightning定义了一个高阶的模型接口LightModel, 封装在torchkeras中, 可以非常方便地训练模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e655a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl \n",
    "import torchmetrics\n",
    "from torchkeras import LightModel \n",
    "\n",
    "class Model(LightModel):\n",
    "    \n",
    "    #loss,and optional metrics\n",
    "    def shared_step(self,batch)->dict:\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = nn.BCELoss()(prediction,y)\n",
    "        preds = torch.where(prediction>0.5,torch.ones_like(prediction),torch.zeros_like(prediction))\n",
    "        acc = torchmetrics.functional.accuracy(preds, y)\n",
    "        dic = {\"loss\":loss,\"accuracy\":acc} \n",
    "        return dic\n",
    "    \n",
    "    #optimizer,and optional lr_scheduler\n",
    "    def configure_optimizers(self):\n",
    "        optimizer= torch.optim.Adagrad(self.parameters(),lr = 0.02)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2999bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 40.6 K\n",
      "------------------------------\n",
      "40.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "40.6 K    Total params\n",
      "0.163     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bae4c103661458a9dbdcf0e4cae0697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The `target` has to be an integer tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a71caa3284e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mckpt_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdl_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, on_epoch)\u001b[0m\n\u001b[1;32m    960\u001b[0m                 \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# capture any logged information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchkeras/lightkeras.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mval_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"val_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-b4246de72902>\u001b[0m in \u001b[0;36mshared_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchmetrics/functional/classification/accuracy.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(preds, target, average, mdmc_average, threshold, top_k, subset_accuracy, num_classes, multiclass, ignore_index)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_squeeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"macro\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"weighted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"none\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchmetrics/functional/classification/accuracy.py\u001b[0m in \u001b[0;36m_mode\u001b[0;34m(preds, target, threshold, top_k, num_classes, multiclass)\u001b[0m\n\u001b[1;32m     35\u001b[0m ) -> DataType:\n\u001b[1;32m     36\u001b[0m     mode = _check_classification_inputs(\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulticlass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchmetrics/utilities/checks.py\u001b[0m in \u001b[0;36m_check_classification_inputs\u001b[0;34m(preds, target, threshold, num_classes, multiclass, top_k)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# Basic validation (that does not need case/type information)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0m_basic_input_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;31m# Check that shape/types fall into one of the cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchmetrics/utilities/checks.py\u001b[0m in \u001b[0;36m_basic_input_validation\u001b[0;34m(preds, target, threshold, multiclass)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `target` has to be an integer tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `target` has to be a non-negative tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `target` has to be an integer tensor."
     ]
    }
   ],
   "source": [
    "pl.seed_everything(1234)\n",
    "net = Net()\n",
    "model = Model(net)\n",
    "\n",
    "ckpt_cb = pl.callbacks.ModelCheckpoint(monitor='val_loss')\n",
    "\n",
    "# set gpus=0 will use cpu，\n",
    "# set gpus=1 will use 1 gpu\n",
    "# set gpus=2 will use 2gpus \n",
    "# set gpus = -1 will use all gpus \n",
    "# you can also set gpus = [0,1] to use the  given gpus\n",
    "# you can even set tpu_cores=2 to use two tpus \n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20,gpus = 0, callbacks=[ckpt_cb]) \n",
    "trainer.fit(model,dl_train,dl_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e845f6e6",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================2021-01-16 21:47:29\n",
    "epoch =  0\n",
    "{'val_loss': 0.6834630966186523, 'val_accuracy': 0.5546000003814697}\n",
    "{'accuracy': 0.5224003791809082, 'loss': 0.7246873378753662}\n",
    "\n",
    "================================================================================2021-01-16 21:48:07\n",
    "epoch =  1\n",
    "{'val_loss': 0.6371415257453918, 'val_accuracy': 0.63319993019104}\n",
    "{'accuracy': 0.6110503673553467, 'loss': 0.6552867889404297}\n",
    "\n",
    "================================================================================2021-01-16 21:48:50\n",
    "epoch =  2\n",
    "{'val_loss': 0.5896139740943909, 'val_accuracy': 0.6798002123832703}\n",
    "{'accuracy': 0.6910000443458557, 'loss': 0.5874115824699402}\n",
    "\n",
    "================================================================================2021-01-16 21:49:32\n",
    "epoch =  3\n",
    "{'val_loss': 0.5726749300956726, 'val_accuracy': 0.6971999406814575}\n",
    "{'accuracy': 0.7391000390052795, 'loss': 0.5251786112785339}\n",
    "\n",
    "================================================================================2021-01-16 21:50:13\n",
    "epoch =  4\n",
    "{'val_loss': 0.5328916311264038, 'val_accuracy': 0.7326000332832336}\n",
    "{'accuracy': 0.7705488801002502, 'loss': 0.4773417115211487}\n",
    "\n",
    "================================================================================2021-01-16 21:50:54\n",
    "epoch =  5\n",
    "{'val_loss': 0.5194208025932312, 'val_accuracy': 0.7413997650146484}\n",
    "{'accuracy': 0.7968998551368713, 'loss': 0.43944093585014343}\n",
    "\n",
    "================================================================================2021-01-16 21:51:35\n",
    "epoch =  6\n",
    "{'val_loss': 0.5199333429336548, 'val_accuracy': 0.7429998517036438}\n",
    "{'accuracy': 0.8130489587783813, 'loss': 0.4102325737476349}\n",
    "\n",
    "================================================================================2021-01-16 21:52:16\n",
    "epoch =  7\n",
    "{'val_loss': 0.5124538540840149, 'val_accuracy': 0.7517998814582825}\n",
    "{'accuracy': 0.8314500451087952, 'loss': 0.3849221169948578}\n",
    "\n",
    "================================================================================2021-01-16 21:52:58\n",
    "epoch =  8\n",
    "{'val_loss': 0.510671079158783, 'val_accuracy': 0.7554002404212952}\n",
    "{'accuracy': 0.8438503742218018, 'loss': 0.3616768419742584}\n",
    "\n",
    "================================================================================2021-01-16 21:53:39\n",
    "epoch =  9\n",
    "{'val_loss': 0.5184627771377563, 'val_accuracy': 0.7530001997947693}\n",
    "{'accuracy': 0.8568001985549927, 'loss': 0.34138554334640503}\n",
    "\n",
    "================================================================================2021-01-16 21:54:20\n",
    "epoch =  10\n",
    "{'val_loss': 0.5105863809585571, 'val_accuracy': 0.7580001354217529}\n",
    "{'accuracy': 0.865899920463562, 'loss': 0.32265418767929077}\n",
    "\n",
    "================================================================================2021-01-16 21:55:02\n",
    "epoch =  11\n",
    "{'val_loss': 0.5222727656364441, 'val_accuracy': 0.7586002349853516}\n",
    "{'accuracy': 0.8747013211250305, 'loss': 0.306064248085022}\n",
    "\n",
    "================================================================================2021-01-16 21:55:43\n",
    "epoch =  12\n",
    "{'val_loss': 0.5208917856216431, 'val_accuracy': 0.7597998976707458}\n",
    "{'accuracy': 0.8820013403892517, 'loss': 0.29068493843078613}\n",
    "\n",
    "================================================================================2021-01-16 21:56:24\n",
    "epoch =  13\n",
    "{'val_loss': 0.5236031413078308, 'val_accuracy': 0.7603999376296997}\n",
    "{'accuracy': 0.889351487159729, 'loss': 0.2765159606933594}\n",
    "\n",
    "================================================================================2021-01-16 21:57:04\n",
    "epoch =  14\n",
    "{'val_loss': 0.5428195595741272, 'val_accuracy': 0.7572000622749329}\n",
    "{'accuracy': 0.8975020051002502, 'loss': 0.26261812448501587}\n",
    "\n",
    "================================================================================2021-01-16 21:57:45\n",
    "epoch =  15\n",
    "{'val_loss': 0.5340956449508667, 'val_accuracy': 0.7602002024650574}\n",
    "{'accuracy': 0.9049026966094971, 'loss': 0.25028231739997864}\n",
    "\n",
    "================================================================================2021-01-16 21:58:25\n",
    "epoch =  16\n",
    "{'val_loss': 0.5380828380584717, 'val_accuracy': 0.7612000107765198}\n",
    "{'accuracy': 0.9085531234741211, 'loss': 0.23980091512203217}\n",
    "\n",
    "================================================================================2021-01-16 21:59:05\n",
    "epoch =  17\n",
    "{'val_loss': 0.5447139739990234, 'val_accuracy': 0.7638000249862671}\n",
    "{'accuracy': 0.9168024659156799, 'loss': 0.22760336101055145}\n",
    "\n",
    "================================================================================2021-01-16 21:59:45\n",
    "epoch =  18\n",
    "{'val_loss': 0.5505074858665466, 'val_accuracy': 0.7636001110076904}\n",
    "{'accuracy': 0.921653687953949, 'loss': 0.21746191382408142}\n",
    "\n",
    "================================================================================2021-01-16 22:00:26\n",
    "epoch =  19\n",
    "{'val_loss': 0.5615255236625671, 'val_accuracy': 0.7634001970291138}\n",
    "{'accuracy': 0.9263033270835876, 'loss': 0.2077799290418625}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25cbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e692ede",
   "metadata": {},
   "source": [
    "### 四，评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d36455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "history = model.history\n",
    "dfhistory = pd.DataFrame(history) \n",
    "dfhistory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb55f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e98782",
   "metadata": {},
   "source": [
    "![](./data/1-3-loss曲线.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c1f2e",
   "metadata": {},
   "source": [
    "![](./data/1-3-accuracy曲线.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ebe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估\n",
    "results = trainer.test(model, test_dataloaders=dl_valid, verbose = False)\n",
    "print(results[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434cd65b",
   "metadata": {},
   "source": [
    "```\n",
    "{'val_loss': 0.5056138457655907, 'val_accuracy': 0.7948000040054322}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72210f2d",
   "metadata": {},
   "source": [
    "### 五，使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ac832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,dl):\n",
    "    model.eval()\n",
    "    result = torch.cat([model.forward(t[0].to(model.device)) for t in dl])\n",
    "    return(result.data)\n",
    "\n",
    "result = predict(model,dl_valid)\n",
    "result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d7fac",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[0.0357],\n",
    "        [0.8699],\n",
    "        [0.3303],\n",
    "        ...,\n",
    "        [0.9962],\n",
    "        [0.5566],\n",
    "        [0.0491]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac76950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a353470e",
   "metadata": {},
   "source": [
    "### 六，保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ckpt_cb.best_model_score)\n",
    "model.load_from_checkpoint(ckpt_cb.best_model_path)\n",
    "\n",
    "best_net  = model.net\n",
    "torch.save(best_net.state_dict(),\"./data/net.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_clone = Net()\n",
    "net_clone.load_state_dict(torch.load(\"./data/net.pt\"))\n",
    "model_clone = Model(net_clone)\n",
    "trainer = pl.Trainer()\n",
    "result = trainer.test(model_clone,test_dataloaders=dl_valid, verbose = False) \n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a207b",
   "metadata": {},
   "source": [
    "```\n",
    "[{'test_loss': 0.4958915710449219, 'test_accuracy': 0.75}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ce17d",
   "metadata": {},
   "source": [
    "**如果本书对你有所帮助，想鼓励一下作者，记得给本项目加一颗星星star⭐️，并分享给你的朋友们喔😊!** \n",
    "\n",
    "如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n",
    "\n",
    "也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n",
    "\n",
    "![算法美食屋logo.png](./data/算法美食屋二维码.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
