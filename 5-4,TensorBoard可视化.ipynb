{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06991d94",
   "metadata": {},
   "source": [
    "# 5-4,TensorBoardå¯è§†åŒ–\n",
    "\n",
    "åœ¨æˆ‘ä»¬çš„ç‚¼ä¸¹è¿‡ç¨‹ä¸­ï¼Œå¦‚æœèƒ½å¤Ÿä½¿ç”¨ä¸°å¯Œçš„å›¾åƒæ¥å±•ç¤ºæ¨¡å‹çš„ç»“æ„ï¼ŒæŒ‡æ ‡çš„å˜åŒ–ï¼Œå‚æ•°çš„åˆ†å¸ƒï¼Œè¾“å…¥çš„å½¢æ€ç­‰ä¿¡æ¯ï¼Œæ— ç–‘ä¼šæå‡æˆ‘ä»¬å¯¹é—®é¢˜çš„æ´å¯ŸåŠ›ï¼Œå¹¶å¢åŠ è®¸å¤šç‚¼ä¸¹çš„ä¹è¶£ã€‚\n",
    "\n",
    "TensorBoardæ­£æ˜¯è¿™æ ·ä¸€ä¸ªç¥å¥‡çš„ç‚¼ä¸¹å¯è§†åŒ–è¾…åŠ©å·¥å…·ã€‚å®ƒåŸæ˜¯TensorFlowçš„å°å¼Ÿï¼Œä½†å®ƒä¹Ÿèƒ½å¤Ÿå¾ˆå¥½åœ°å’ŒPytorchè¿›è¡Œé…åˆã€‚ç”šè‡³åœ¨Pytorchä¸­ä½¿ç”¨TensorBoardæ¯”TensorFlowä¸­ä½¿ç”¨TensorBoardè¿˜è¦æ¥çš„æ›´åŠ ç®€å•å’Œè‡ªç„¶ã€‚\n",
    "\n",
    "Pytorchä¸­åˆ©ç”¨TensorBoardå¯è§†åŒ–çš„å¤§æ¦‚è¿‡ç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "é¦–å…ˆåœ¨Pytorchä¸­æŒ‡å®šä¸€ä¸ªç›®å½•åˆ›å»ºä¸€ä¸ªtorch.utils.tensorboard.SummaryWriteræ—¥å¿—å†™å…¥å™¨ã€‚\n",
    "\n",
    "ç„¶åæ ¹æ®éœ€è¦å¯è§†åŒ–çš„ä¿¡æ¯ï¼Œåˆ©ç”¨æ—¥å¿—å†™å…¥å™¨å°†ç›¸åº”ä¿¡æ¯æ—¥å¿—å†™å…¥æˆ‘ä»¬æŒ‡å®šçš„ç›®å½•ã€‚\n",
    "\n",
    "æœ€åå°±å¯ä»¥ä¼ å…¥æ—¥å¿—ç›®å½•ä½œä¸ºå‚æ•°å¯åŠ¨TensorBoardï¼Œç„¶åå°±å¯ä»¥åœ¨TensorBoardä¸­æ„‰å¿«åœ°çœ‹ç‰‡äº†ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä¸»è¦ä»‹ç»Pytorchä¸­åˆ©ç”¨TensorBoardè¿›è¡Œå¦‚ä¸‹æ–¹é¢ä¿¡æ¯çš„å¯è§†åŒ–çš„æ–¹æ³•ã€‚\n",
    "\n",
    "* å¯è§†åŒ–æ¨¡å‹ç»“æ„ï¼š writer.add_graph\n",
    "\n",
    "* å¯è§†åŒ–æŒ‡æ ‡å˜åŒ–ï¼š writer.add_scalar\n",
    "\n",
    "* å¯è§†åŒ–å‚æ•°åˆ†å¸ƒï¼š writer.add_histogram\n",
    "\n",
    "* å¯è§†åŒ–åŸå§‹å›¾åƒï¼š writer.add_image æˆ– writer.add_images\n",
    "\n",
    "* å¯è§†åŒ–äººå·¥ç»˜å›¾ï¼š writer.add_figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd672ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "908773d9",
   "metadata": {},
   "source": [
    "### ä¸€ï¼Œå¯è§†åŒ–æ¨¡å‹ç»“æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cd595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/metrics/__init__.py:44: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  \"`pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package\"\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchkeras import Model,summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45258601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size = 3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2,stride = 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5)\n",
    "        self.dropout = nn.Dropout2d(p = 0.1)\n",
    "        self.adaptive_pool = nn.AdaptiveMaxPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(64,32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(32,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        y = self.sigmoid(x)\n",
    "        return y\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb962553",
   "metadata": {},
   "source": [
    "```\n",
    "Net(\n",
    "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
    "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
    "  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
    "  (flatten): Flatten()\n",
    "  (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
    "  (relu): ReLU()\n",
    "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
    "  (sigmoid): Sigmoid()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c752c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             896\n",
      "         MaxPool2d-2           [-1, 32, 15, 15]               0\n",
      "            Conv2d-3           [-1, 64, 11, 11]          51,264\n",
      "         MaxPool2d-4             [-1, 64, 5, 5]               0\n",
      "         Dropout2d-5             [-1, 64, 5, 5]               0\n",
      " AdaptiveMaxPool2d-6             [-1, 64, 1, 1]               0\n",
      "           Flatten-7                   [-1, 64]               0\n",
      "            Linear-8                   [-1, 32]           2,080\n",
      "              ReLU-9                   [-1, 32]               0\n",
      "           Linear-10                    [-1, 1]              33\n",
      "          Sigmoid-11                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 54,273\n",
      "Trainable params: 54,273\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.011719\n",
      "Forward/backward pass size (MB): 0.359634\n",
      "Params size (MB): 0.207035\n",
      "Estimated Total Size (MB): 0.578388\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "summary(net,input_shape= (3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54aa921",
   "metadata": {},
   "source": [
    "```\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv2d-1           [-1, 32, 30, 30]             896\n",
    "         MaxPool2d-2           [-1, 32, 15, 15]               0\n",
    "            Conv2d-3           [-1, 64, 11, 11]          51,264\n",
    "         MaxPool2d-4             [-1, 64, 5, 5]               0\n",
    "         Dropout2d-5             [-1, 64, 5, 5]               0\n",
    " AdaptiveMaxPool2d-6             [-1, 64, 1, 1]               0\n",
    "           Flatten-7                   [-1, 64]               0\n",
    "            Linear-8                   [-1, 32]           2,080\n",
    "              ReLU-9                   [-1, 32]               0\n",
    "           Linear-10                    [-1, 1]              33\n",
    "          Sigmoid-11                    [-1, 1]               0\n",
    "================================================================\n",
    "Total params: 54,273\n",
    "Trainable params: 54,273\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.011719\n",
    "Forward/backward pass size (MB): 0.359634\n",
    "Params size (MB): 0.207035\n",
    "Estimated Total Size (MB): 0.578388\n",
    "----------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d8305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_graph(net,input_to_model = torch.rand(1,3,32,32))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222eebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "#%tensorboard --logdir ./data/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20744ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No known TensorBoard instances running.\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "#æŸ¥çœ‹å¯åŠ¨çš„tensorboardç¨‹åº\n",
    "notebook.list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2b7aee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d116e223b37367f9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d116e223b37367f9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#å¯åŠ¨tensorboardç¨‹åº\n",
    "notebook.start(\"--logdir ./data/tensorboard\")\n",
    "#ç­‰ä»·äºåœ¨å‘½ä»¤è¡Œä¸­æ‰§è¡Œ tensorboard --logdir ./data/tensorboard\n",
    "#å¯ä»¥åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ http://localhost:6006/ æŸ¥çœ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4920951a",
   "metadata": {},
   "source": [
    "![](./data/5-4-graphç»“æ„.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6017034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b39ef6ae",
   "metadata": {},
   "source": [
    "### äºŒï¼Œå¯è§†åŒ–æŒ‡æ ‡å˜åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c81a0",
   "metadata": {},
   "source": [
    "æœ‰æ—¶å€™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¦‚æœèƒ½å¤Ÿå®æ—¶åŠ¨æ€åœ°æŸ¥çœ‹losså’Œå„ç§metricçš„å˜åŒ–æ›²çº¿ï¼Œé‚£ä¹ˆæ— ç–‘å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´åŠ ç›´è§‚åœ°äº†è§£æ¨¡å‹çš„è®­ç»ƒæƒ…å†µã€‚\n",
    "\n",
    "æ³¨æ„ï¼Œwriter.add_scalarä»…èƒ½å¯¹æ ‡é‡çš„å€¼çš„å˜åŒ–è¿›è¡Œå¯è§†åŒ–ã€‚å› æ­¤å®ƒä¸€èˆ¬ç”¨äºå¯¹losså’Œmetricçš„å˜åŒ–è¿›è¡Œå¯è§†åŒ–åˆ†æã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9227ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y= tensor(0.) ; x= tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# f(x) = a*x**2 + b*x + cçš„æœ€å°å€¼\n",
    "x = torch.tensor(0.0,requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "a = torch.tensor(1.0)\n",
    "b = torch.tensor(-2.0)\n",
    "c = torch.tensor(1.0)\n",
    "\n",
    "optimizer = torch.optim.SGD(params=[x],lr = 0.01)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    result = a*torch.pow(x,2) + b*x + c \n",
    "    return(result)\n",
    "\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "for i in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    optimizer.step()\n",
    "    writer.add_scalar(\"x\",x.item(),i) #æ—¥å¿—ä¸­è®°å½•xåœ¨ç¬¬step i çš„å€¼\n",
    "    writer.add_scalar(\"y\",y.item(),i) #æ—¥å¿—ä¸­è®°å½•yåœ¨ç¬¬step i çš„å€¼\n",
    "\n",
    "writer.close()\n",
    "    \n",
    "print(\"y=\",f(x).data,\";\",\"x=\",x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da722fb3",
   "metadata": {},
   "source": [
    "```\n",
    "y= tensor(0.) ; x= tensor(1.0000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d40ad",
   "metadata": {},
   "source": [
    "![](./data/5-4-æŒ‡æ ‡å˜åŒ–.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05f42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7f602a9",
   "metadata": {},
   "source": [
    "### ä¸‰ï¼Œå¯è§†åŒ–å‚æ•°åˆ†å¸ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa31a28",
   "metadata": {},
   "source": [
    "å¦‚æœéœ€è¦å¯¹æ¨¡å‹çš„å‚æ•°(ä¸€èˆ¬éæ ‡é‡)åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„å˜åŒ–è¿›è¡Œå¯è§†åŒ–ï¼Œå¯ä»¥ä½¿ç”¨ writer.add_histogramã€‚\n",
    "\n",
    "å®ƒèƒ½å¤Ÿè§‚æµ‹å¼ é‡å€¼åˆ†å¸ƒçš„ç›´æ–¹å›¾éšè®­ç»ƒæ­¥éª¤çš„å˜åŒ–è¶‹åŠ¿ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "188e88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# åˆ›å»ºæ­£æ€åˆ†å¸ƒçš„å¼ é‡æ¨¡æ‹Ÿå‚æ•°çŸ©é˜µ\n",
    "def norm(mean,std):\n",
    "    t = std*torch.randn((100,20)) + mean\n",
    "    return t\n",
    "\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "for step,mean in enumerate(range(-10,10,1)):\n",
    "    w = norm(mean,1)\n",
    "    writer.add_histogram(\"w\",w, step)\n",
    "    writer.flush()\n",
    "writer.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3952e6",
   "metadata": {},
   "source": [
    "![](./data/5-4-å¼ é‡åˆ†å¸ƒ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1e5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0b5367d",
   "metadata": {},
   "source": [
    "### å››ï¼Œå¯è§†åŒ–åŸå§‹å›¾åƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72206d",
   "metadata": {},
   "source": [
    "å¦‚æœæˆ‘ä»¬åšå›¾åƒç›¸å…³çš„ä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥å°†åŸå§‹çš„å›¾ç‰‡åœ¨tensorboardä¸­è¿›è¡Œå¯è§†åŒ–å±•ç¤ºã€‚\n",
    "\n",
    "å¦‚æœåªå†™å…¥ä¸€å¼ å›¾ç‰‡ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨writer.add_imageã€‚\n",
    "\n",
    "å¦‚æœè¦å†™å…¥å¤šå¼ å›¾ç‰‡ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨writer.add_imagesã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥ç”¨ torchvision.utils.make_gridå°†å¤šå¼ å›¾ç‰‡æ‹¼æˆä¸€å¼ å›¾ç‰‡ï¼Œç„¶åç”¨writer.add_imageå†™å…¥ã€‚\n",
    "\n",
    "æ³¨æ„ï¼Œä¼ å…¥çš„æ˜¯ä»£è¡¨å›¾ç‰‡ä¿¡æ¯çš„Pytorchä¸­çš„å¼ é‡æ•°æ®ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,datasets \n",
    "\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "transform_valid = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.ImageFolder(\"./data/cifar2/train/\",\n",
    "            transform = transform_train,target_transform= lambda t:torch.tensor([t]).float())\n",
    "ds_valid = datasets.ImageFolder(\"./data/cifar2/test/\",\n",
    "            transform = transform_train,target_transform= lambda t:torch.tensor([t]).float())\n",
    "\n",
    "print(ds_train.class_to_idx)\n",
    "\n",
    "dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True,num_workers=3)\n",
    "dl_valid = DataLoader(ds_valid,batch_size = 50,shuffle = True,num_workers=3)\n",
    "\n",
    "dl_train_iter = iter(dl_train)\n",
    "images, labels = dl_train_iter.next()\n",
    "\n",
    "# ä»…æŸ¥çœ‹ä¸€å¼ å›¾ç‰‡\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_image('images[0]', images[0])\n",
    "writer.close()\n",
    "\n",
    "# å°†å¤šå¼ å›¾ç‰‡æ‹¼æ¥æˆä¸€å¼ å›¾ç‰‡ï¼Œä¸­é—´ç”¨é»‘è‰²ç½‘æ ¼åˆ†å‰²\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('image_grid', img_grid)\n",
    "writer.close()\n",
    "\n",
    "# å°†å¤šå¼ å›¾ç‰‡ç›´æ¥å†™å…¥\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_images(\"images\",images,global_step = 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd12bfe",
   "metadata": {},
   "source": [
    "```\n",
    "{'0_airplane': 0, '1_automobile': 1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1fef8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e5df737",
   "metadata": {},
   "source": [
    "![](./data/5-4-åŸå§‹å›¾åƒå¯è§†åŒ–.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb4c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18374287",
   "metadata": {},
   "source": [
    "### äº”ï¼Œå¯è§†åŒ–äººå·¥ç»˜å›¾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e89fd4",
   "metadata": {},
   "source": [
    "å¦‚æœæˆ‘ä»¬å°†matplotlibç»˜å›¾çš„ç»“æœå† tensorboardä¸­å±•ç¤ºï¼Œå¯ä»¥ä½¿ç”¨ add_figure.\n",
    "\n",
    "æ³¨æ„ï¼Œå’Œwriter.add_imageä¸åŒçš„æ˜¯ï¼Œwriter.add_figureéœ€è¦ä¼ å…¥matplotlibçš„figureå¯¹è±¡ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fba68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,datasets \n",
    "\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "transform_valid = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "ds_train = datasets.ImageFolder(\"./data/cifar2/train/\",\n",
    "            transform = transform_train,target_transform= lambda t:torch.tensor([t]).float())\n",
    "ds_valid = datasets.ImageFolder(\"./data/cifar2/test/\",\n",
    "            transform = transform_train,target_transform= lambda t:torch.tensor([t]).float())\n",
    "\n",
    "print(ds_train.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b140d",
   "metadata": {},
   "source": [
    "```\n",
    "{'0_airplane': 0, '1_automobile': 1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae565b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "figure = plt.figure(figsize=(8,8)) \n",
    "for i in range(9):\n",
    "    img,label = ds_train[i]\n",
    "    img = img.permute(1,2,0)\n",
    "    ax=plt.subplot(3,3,i+1)\n",
    "    ax.imshow(img.numpy())\n",
    "    ax.set_title(\"label = %d\"%label.item())\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6ae66",
   "metadata": {},
   "source": [
    "![](./data/5-4-ä¹å®«æ ¼.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65444d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_figure('figure',figure,global_step=0)\n",
    "writer.close()                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc1cc0",
   "metadata": {},
   "source": [
    "![](./data/5-4-å¯è§†åŒ–äººå·¥ç»˜å›¾.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecffb59",
   "metadata": {},
   "source": [
    "**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** \n",
    "\n",
    "å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·\"ç®—æ³•ç¾é£Ÿå±‹\"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚\n",
    "\n",
    "![ç®—æ³•ç¾é£Ÿå±‹logo.png](./data/ç®—æ³•ç¾é£Ÿå±‹äºŒç»´ç .jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a0e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ba92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
